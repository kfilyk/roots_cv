{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1bd49-9ee9-444b-a65e-2402f9e2c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "\n",
    "from utils import ObjectDetectionPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cced9-2d36-45ac-8318-4ec43d6682ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0dcba-db10-497c-8ec5-b6ede1c27fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_dir = os.path.join(\"s3://ava-cv-raw-photo-bucket\", \"10-plants\", \"GoogleImages\")\n",
    "local_dir = os.path.join(\"images\", \"10-plants\", \"GoogleImages\")\n",
    "if not os.path.isdir(local_dir):\n",
    "    !aws s3 cp {bucket_dir} {local_dir} --recursive --only-show-errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41041715-1393-43dc-87f5-51e60f6e9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictor = ObjectDetectionPredictor(\n",
    "    model_id=os.environ[\"OBJECT_DETECTION_MODEL_ID\"],\n",
    "    model_version=os.environ[\"OBJECT_DETECTION_MODEL_VERSION\"],\n",
    "    instance_type=os.environ[\"INFERENCE_INSTANCE_TYPE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cc000-478a-49f5-b7a7-8272ffa14b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_predictor.deploy(\n",
    "    instance_type=os.environ[\"INFERENCE_INSTANCE_TYPE\"],\n",
    "    instance_count=int(os.environ[\"INFERENCE_INSTANCE_COUNT\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d70ed6-8459-4af9-81fe-f0315ceedd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "min_confidence = 0.1\n",
    "classes_to_keep = [\"potted plant\"]\n",
    "\n",
    "for root, dirs, files in os.walk(os.path.join(\"images\", \"10-plants\", \"GoogleImages\")):\n",
    "    if \".ipynb_checkpoints\" in root:\n",
    "        continue\n",
    "    \n",
    "    if dirs and not files:\n",
    "        for dir in dirs:\n",
    "            new_dir = os.path.join(root, dir).replace(\"GoogleImages\", \"CroppedGoogleImages\")\n",
    "            if not os.path.isdir(new_dir):\n",
    "                os.makedirs(new_dir)\n",
    "        continue\n",
    "            \n",
    "    image_filenames = [file for file in files if file.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    with tqdm(image_filenames, position=0, leave=True) as pbar:\n",
    "        for image_filename in pbar:\n",
    "            image_path = os.path.join(root, image_filename)\n",
    "            pbar.set_description(image_path)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_np = np.array(image)\n",
    "            with open(image_path, \"rb\") as file:\n",
    "                image_binary = file.read()\n",
    "            try:\n",
    "                normalized_boxes, classes_names, confidences, labels = model_predictor.predict(image_binary)\n",
    "            except Exception as exc:\n",
    "                print(f\"Exception occured when predicting bounding boxes. Skipping {image_path}...\")\n",
    "                continue\n",
    "\n",
    "            n_boxes = len(normalized_boxes)\n",
    "            normalized_boxes = [\n",
    "                normalized_boxes[i] for i in range(n_boxes)\n",
    "                if confidences[i] >= min_confidence and classes_names[i] in classes_to_keep\n",
    "            ]\n",
    "\n",
    "            cropped_images = []\n",
    "            for normalized_box in normalized_boxes:\n",
    "                left, top, right, bot = normalized_box\n",
    "                left, right = [val * image_np.shape[1] for val in [left, right]]\n",
    "                bot, top = [val * image_np.shape[0] for val in [bot, top]]\n",
    "                cropped_image = image.crop((left, top, right, bot))\n",
    "                cropped_images.append(cropped_image)\n",
    "                \n",
    "            # if no bounding boxes were found, save the original image\n",
    "            if not cropped_images:\n",
    "                cropped_images = [image]\n",
    "\n",
    "            for i, cropped_image in enumerate(cropped_images):\n",
    "                save_path = os.path.join(\n",
    "                    root.replace(\"GoogleImages\", \"CroppedGoogleImages\"),\n",
    "                    re.sub(r\"\\.(jpe?g|png)\", f\"-{i}.jpg\", image_filename)\n",
    "                )\n",
    "                cropped_image.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a1f0b-07d0-4e16-8206-980478c61b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictor.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d56324e-55a4-4525-8b4e-d9adb9b8636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "local_dir = local_dir.replace(\"GoogleImages\", \"CroppedGoogleImages\")\n",
    "bucket_dir = bucket_dir.replace(\"GoogleImages\", \"CroppedGoogleImages\")\n",
    "!aws s3 cp {local_dir} {bucket_dir} --recursive --only-show-errors --exclude \"*\" --include \"*.jpg\" --include \"*.jpeg\" --include \"*.png\""
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ca-central-1:310906938811:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
